{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Retail - Basic Exploration\n",
    "* Download the data file\n",
    "* Visualize the first 10 rows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To edit this notebook, go to File -> Save a copy in Drive\n",
    "Google Colab is a freemium cloud service based on Jupyter notebooks. It provides a virtual machine (VM) in which a Jupyter notebook can be executed, even with hardware acceleration like GPUs. The whole process is similar to Google borrowing us one of its computers. We can access this borrowed computer through this browser window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "a = 10\n",
    "b = 25\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8750\n"
     ]
    }
   ],
   "source": [
    "product = a * b \n",
    "sum = a + b\n",
    "result = product * sum\n",
    "print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading \n",
    "A virtual machine is the simultion of a computer operating system (e.g. Windows or Linux) on another computer. Basically, it allows you to run an OS inside another OS. Mac Users may know this from Parallels Desktop, which allows to use Windows inside of Mac OS. Because a VM acts as another computer (that is trapped inside another computer), we have to download our dataset inside this virtual computer system. We can again do this using linux commands. **You don't have to understand the following code, it's enough to understand that you can operate a computer entirely using a command line, which includes downloading and unzipping zip-files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# URL of the ZIP file to download\n",
    "url = \"https://faubox.rrze.uni-erlangen.de/dl/fitrNLfAzeMvpher2zfyA/online_retail_II.zip\"\n",
    "\n",
    "# Path to save the downloaded ZIP file\n",
    "zip_filename = \"online_retail_II.zip\"\n",
    "\n",
    "# Path to extract the desired file from the ZIP archive\n",
    "extracted_file = \"online_retail_II.xlsx\"\n",
    "\n",
    "# Download the ZIP file\n",
    "response = requests.get(url)\n",
    "with open(zip_filename, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Extract the desired file from the ZIP archive\n",
    "with zipfile.ZipFile(zip_filename, \"r\") as zip_ref:\n",
    "    zip_ref.extract(extracted_file)\n",
    "\n",
    "print(\"File extracted successfully.\")\n",
    "data_file = extracted_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file into a Pandas data frame and showing the contents of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# reads this into a dictionary for every sheet in the excel file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m raw_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel(data_file, sheet_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# raw_data.values() returns a list of identical data frames that are simply stacked\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(raw_data\u001b[39m.\u001b[39mvalues())\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:490\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    485\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    486\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m     )\n\u001b[0;32m    489\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 490\u001b[0m     data \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mparse(\n\u001b[0;32m    491\u001b[0m         sheet_name\u001b[39m=\u001b[39msheet_name,\n\u001b[0;32m    492\u001b[0m         header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m    493\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m    494\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m    495\u001b[0m         usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m    496\u001b[0m         squeeze\u001b[39m=\u001b[39msqueeze,\n\u001b[0;32m    497\u001b[0m         dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    498\u001b[0m         converters\u001b[39m=\u001b[39mconverters,\n\u001b[0;32m    499\u001b[0m         true_values\u001b[39m=\u001b[39mtrue_values,\n\u001b[0;32m    500\u001b[0m         false_values\u001b[39m=\u001b[39mfalse_values,\n\u001b[0;32m    501\u001b[0m         skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[0;32m    502\u001b[0m         nrows\u001b[39m=\u001b[39mnrows,\n\u001b[0;32m    503\u001b[0m         na_values\u001b[39m=\u001b[39mna_values,\n\u001b[0;32m    504\u001b[0m         keep_default_na\u001b[39m=\u001b[39mkeep_default_na,\n\u001b[0;32m    505\u001b[0m         na_filter\u001b[39m=\u001b[39mna_filter,\n\u001b[0;32m    506\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    507\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[0;32m    508\u001b[0m         date_parser\u001b[39m=\u001b[39mdate_parser,\n\u001b[0;32m    509\u001b[0m         thousands\u001b[39m=\u001b[39mthousands,\n\u001b[0;32m    510\u001b[0m         decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m    511\u001b[0m         comment\u001b[39m=\u001b[39mcomment,\n\u001b[0;32m    512\u001b[0m         skipfooter\u001b[39m=\u001b[39mskipfooter,\n\u001b[0;32m    513\u001b[0m         convert_float\u001b[39m=\u001b[39mconvert_float,\n\u001b[0;32m    514\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39mmangle_dupe_cols,\n\u001b[0;32m    515\u001b[0m     )\n\u001b[0;32m    516\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     \u001b[39m# make sure to close opened file handles\u001b[39;00m\n\u001b[0;32m    518\u001b[0m     \u001b[39mif\u001b[39;00m should_close:\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1734\u001b[0m, in \u001b[0;36mExcelFile.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m   1700\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\n\u001b[0;32m   1701\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1702\u001b[0m     sheet_name: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1722\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, DataFrame] \u001b[39m|\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mint\u001b[39m, DataFrame]:\n\u001b[0;32m   1723\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1724\u001b[0m \u001b[39m    Parse specified sheet(s) into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1725\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1732\u001b[0m \u001b[39m        DataFrame from the passed in Excel file.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mparse(\n\u001b[0;32m   1735\u001b[0m         sheet_name\u001b[39m=\u001b[39msheet_name,\n\u001b[0;32m   1736\u001b[0m         header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   1737\u001b[0m         names\u001b[39m=\u001b[39mnames,\n\u001b[0;32m   1738\u001b[0m         index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[0;32m   1739\u001b[0m         usecols\u001b[39m=\u001b[39musecols,\n\u001b[0;32m   1740\u001b[0m         squeeze\u001b[39m=\u001b[39msqueeze,\n\u001b[0;32m   1741\u001b[0m         converters\u001b[39m=\u001b[39mconverters,\n\u001b[0;32m   1742\u001b[0m         true_values\u001b[39m=\u001b[39mtrue_values,\n\u001b[0;32m   1743\u001b[0m         false_values\u001b[39m=\u001b[39mfalse_values,\n\u001b[0;32m   1744\u001b[0m         skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[0;32m   1745\u001b[0m         nrows\u001b[39m=\u001b[39mnrows,\n\u001b[0;32m   1746\u001b[0m         na_values\u001b[39m=\u001b[39mna_values,\n\u001b[0;32m   1747\u001b[0m         parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[0;32m   1748\u001b[0m         date_parser\u001b[39m=\u001b[39mdate_parser,\n\u001b[0;32m   1749\u001b[0m         thousands\u001b[39m=\u001b[39mthousands,\n\u001b[0;32m   1750\u001b[0m         comment\u001b[39m=\u001b[39mcomment,\n\u001b[0;32m   1751\u001b[0m         skipfooter\u001b[39m=\u001b[39mskipfooter,\n\u001b[0;32m   1752\u001b[0m         convert_float\u001b[39m=\u001b[39mconvert_float,\n\u001b[0;32m   1753\u001b[0m         mangle_dupe_cols\u001b[39m=\u001b[39mmangle_dupe_cols,\n\u001b[0;32m   1754\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds,\n\u001b[0;32m   1755\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:765\u001b[0m, in \u001b[0;36mBaseExcelReader.parse\u001b[1;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m     sheet \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sheet_by_index(asheetname)\n\u001b[0;32m    764\u001b[0m file_rows_needed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001b[1;32m--> 765\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_sheet_data(sheet, convert_float, file_rows_needed)\n\u001b[0;32m    766\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(sheet, \u001b[39m\"\u001b[39m\u001b[39mclose\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    767\u001b[0m     \u001b[39m# pyxlsb opens two TemporaryFiles\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     sheet\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:615\u001b[0m, in \u001b[0;36mOpenpyxlReader.get_sheet_data\u001b[1;34m(self, sheet, convert_float, file_rows_needed)\u001b[0m\n\u001b[0;32m    613\u001b[0m data: \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[Scalar]] \u001b[39m=\u001b[39m []\n\u001b[0;32m    614\u001b[0m last_row_with_data \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m--> 615\u001b[0m \u001b[39mfor\u001b[39;00m row_number, row \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sheet\u001b[39m.\u001b[39mrows):\n\u001b[0;32m    616\u001b[0m     converted_row \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_cell(cell, convert_float) \u001b[39mfor\u001b[39;00m cell \u001b[39min\u001b[39;00m row]\n\u001b[0;32m    617\u001b[0m     \u001b[39mwhile\u001b[39;00m converted_row \u001b[39mand\u001b[39;00m converted_row[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    618\u001b[0m         \u001b[39m# trim trailing empty elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:81\u001b[0m, in \u001b[0;36mReadOnlyWorksheet._cells_by_row\u001b[1;34m(self, min_col, min_row, max_col, max_row, values_only)\u001b[0m\n\u001b[0;32m     77\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_source()\n\u001b[0;32m     78\u001b[0m parser \u001b[39m=\u001b[39m WorkSheetParser(src, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shared_strings,\n\u001b[0;32m     79\u001b[0m                          data_only\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mdata_only, epoch\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mepoch,\n\u001b[0;32m     80\u001b[0m                          date_formats\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39m_date_formats)\n\u001b[1;32m---> 81\u001b[0m \u001b[39mfor\u001b[39;00m idx, row \u001b[39min\u001b[39;00m parser\u001b[39m.\u001b[39mparse():\n\u001b[0;32m     82\u001b[0m     \u001b[39mif\u001b[39;00m max_row \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m idx \u001b[39m>\u001b[39m max_row:\n\u001b[0;32m     83\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\site-packages\\openpyxl\\worksheet\\_reader.py:156\u001b[0m, in \u001b[0;36mWorkSheetParser.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    137\u001b[0m properties \u001b[39m=\u001b[39m {\n\u001b[0;32m    138\u001b[0m     PRINT_TAG: (\u001b[39m'\u001b[39m\u001b[39mprint_options\u001b[39m\u001b[39m'\u001b[39m, PrintOptions),\n\u001b[0;32m    139\u001b[0m     MARGINS_TAG: (\u001b[39m'\u001b[39m\u001b[39mpage_margins\u001b[39m\u001b[39m'\u001b[39m, PageMargins),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    151\u001b[0m \n\u001b[0;32m    152\u001b[0m }\n\u001b[0;32m    154\u001b[0m it \u001b[39m=\u001b[39m iterparse(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource) \u001b[39m# add a finaliser to close the source when this becomes possible\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m \u001b[39mfor\u001b[39;00m _, element \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    157\u001b[0m     tag_name \u001b[39m=\u001b[39m element\u001b[39m.\u001b[39mtag\n\u001b[0;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m tag_name \u001b[39min\u001b[39;00m dispatcher:\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\xml\\etree\\ElementTree.py:1251\u001b[0m, in \u001b[0;36miterparse.<locals>.iterator\u001b[1;34m(source)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[39myield from\u001b[39;00m pullparser\u001b[39m.\u001b[39mread_events()\n\u001b[0;32m   1250\u001b[0m \u001b[39m# load event buffer\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m data \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39mread(\u001b[39m16\u001b[39m \u001b[39m*\u001b[39m \u001b[39m1024\u001b[39m)\n\u001b[0;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[0;32m   1253\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\zipfile.py:953\u001b[0m, in \u001b[0;36mZipExtFile.read\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    952\u001b[0m \u001b[39mwhile\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eof:\n\u001b[1;32m--> 953\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read1(n)\n\u001b[0;32m    954\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[0;32m    955\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_readbuffer \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\zipfile.py:1021\u001b[0m, in \u001b[0;36mZipExtFile._read1\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail\n\u001b[0;32m   1020\u001b[0m     \u001b[39mif\u001b[39;00m n \u001b[39m>\u001b[39m \u001b[39mlen\u001b[39m(data):\n\u001b[1;32m-> 1021\u001b[0m         data \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read2(n \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(data))\n\u001b[0;32m   1022\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1023\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read2(n)\n",
      "File \u001b[1;32mc:\\Users\\Schiendorfer\\Anaconda3\\envs\\onlineretail\\Lib\\zipfile.py:1056\u001b[0m, in \u001b[0;36mZipExtFile._read2\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compress_left \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data)\n\u001b[0;32m   1055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decrypter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1059\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decrypter(data)\n",
      "\u001b[1;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# reads this into a dictionary for every sheet in the excel file\n",
    "raw_data = pd.read_excel(data_file, sheet_name=None)\n",
    "# raw_data.values() returns a list of identical data frames that are simply stacked\n",
    "df = pd.concat(raw_data.values())\n",
    "# Reset the index and assign a new unique index\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index and assign a new unique index\n",
    "df = df.reset_index(drop=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first ten rows of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the ten first, we can randomly sample some rows from our data set. Repeat this a couple of times to get a feeling for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmup questions first:\n",
    "* How many rows do we have in our dataset? Hint: use df.shape or print(df) \t\n",
    "* How many customer IDs are NaN? \n",
    "* What was the highest price for a product?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows do we have in our dataset? Hint: use df.shape or print(df) \n",
    "print(df.shape)\n",
    "num_rows = df.shape[0]\n",
    "print(f\"We have {num_rows} rows in our dataset.\")\n",
    "\n",
    "# How many customer IDs are NaN? \n",
    "df[\"Customer ID\"].isna()\n",
    "NaN_Customers = df[\"Customer ID\"].isna().sum()\n",
    "print(f\"We have {NaN_Customers} unidentified customers.\")\n",
    "\n",
    "# What was the highest price for a product?\n",
    "most_expensive = df[\"Price\"].max()\n",
    "print(f\"The most expensive price was {most_expensive}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[index_of_max_price]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What countries do most our customers come from?\t\n",
    "* What was our most expensive sale?\t\n",
    "* Which customer ordered the most products?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the first one: What countries do most our customers come from?\t\n",
    "df[\"Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many different countries do we have?\n",
    "print(df[\"Country\"].nunique())\n",
    "\n",
    "df[\"Country\"].value_counts(normalize=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was our most expensive sale?\t\n",
    "\n",
    "# Find the index of the row with the highest price\n",
    "index_of_max_price = df['Price'].idxmax()\n",
    "\n",
    "# Get the StockCode of the item with the highest price\n",
    "max_price_item = df.loc[index_of_max_price]\n",
    "max_price_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering (\"where\" in SQL)\n",
    "actual_sales = df[df[\"Quantity\"] > 0]\n",
    "# Find the index of the row with the highest price\n",
    "index_of_max_price = actual_sales['Price'].idxmax()\n",
    "\n",
    "# Get the StockCode of the item with the highest price\n",
    "max_price_item = actual_sales.loc[index_of_max_price]\n",
    "max_price_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's talk about indexing with a boolean expression\n",
    "df[\"Quantity\"] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which customer ordered the most products?\n",
    "\n",
    "# Group the DataFrame by 'Customer ID' and calculate the sum of 'Quantity' for each customer\n",
    "customer_quantity = df.groupby('Customer ID')['Quantity'].sum()\n",
    "\n",
    "# Find the customer with the highest total quantity\n",
    "customer_with_most_items = customer_quantity.idxmax()\n",
    "\n",
    "print(\"Customer ID with the most items:\")\n",
    "customer_quantity.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onlineretail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
